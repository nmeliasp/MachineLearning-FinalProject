{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of people in data set =  146\n",
      "features for every person in the data set:\n",
      "['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmeli\\Documents\\Udacity\\Data Analysis\\Anacondas\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "#features_list = ['poi','salary','bonus','total_stock_value','exercised_stock_options','total_payments','long_term_incentive'] # You will need to use more features\n",
    "financial_features_list = ['poi','salary','bonus','deferral_payments','deferred_income','director_fees','exercised_stock_options','expenses','loan_advances','long_term_incentive','restricted_stock','restricted_stock_deferred','total_payments','total_stock_value']\n",
    "email_feature_list = ['poi','to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "print 'number of people in data set = ', len(data_dict)\n",
    "print 'features for every person in the data set:\\n', data_dict['LAY KENNETH L'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data set before removing outlier =  146\n",
      "length of data set after removing outlier =  145\n"
     ]
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "''' as seen in the outliers section, we saw that there was a \"Total\" entry in the data set that was a clear outlier.\n",
    "thus we are removing it\n",
    "'''\n",
    "print \"length of data set before removing outlier = \", len(data_dict)\n",
    "data_dict.pop(\"TOTAL\",0)\n",
    "print \"length of data set after removing outlier = \", len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, i am going to extract the features i defined in my list above and select the top 4 features from the financial features and from the email features to help aid my classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing financial_features k scores: \n",
      "[ 18.57570327  21.06000171   0.21705893  11.59554766   2.10765594\n",
      "  25.09754153   6.23420114   7.2427304   10.07245453   9.34670079\n",
      "   0.06498431   8.86672154  24.46765405]\n",
      "printing email_features k scores: \n",
      "[ 0.29296869  2.43137891  0.46640016  1.0853069   4.61945732]\n"
     ]
    }
   ],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import numpy\n",
    "# extract the 4 strongest features from the financial data with SelectKBest\n",
    "financial_data = featureFormat(my_dataset, financial_features_list, sort_keys = True)\n",
    "financial_labels, financial_features = targetFeatureSplit(financial_data)\n",
    "\n",
    "# select 4 best features using SelectKBest\n",
    "test1 = SelectKBest(k=4)\n",
    "fit1 = test1.fit(financial_features,financial_labels)\n",
    "\n",
    "#numpy.set_printoptions(precision=10)\n",
    "print \"printing financial_features k scores: \\n\", (fit1.scores_)\n",
    "\n",
    "feature = fit1.transform(financial_features)\n",
    "# summarize selected features\n",
    "#print(feature)\n",
    "\n",
    "#print features\n",
    "#print labels\n",
    "#print financial_features[3]\n",
    "\n",
    "#extract the 4 strongest features from email data with SelectKBest\n",
    "email_data = featureFormat(my_dataset, email_feature_list, sort_keys = True)\n",
    "email_labels, email_features = targetFeatureSplit(email_data)\n",
    "\n",
    "test2 = SelectKBest(k=4)\n",
    "fit2 = test2.fit(email_features,email_labels)\n",
    "\n",
    "print \"printing email_features k scores: \\n\", (fit2.scores_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running SelectKBest seperately on the Finanical Data and Email Data. The following features were identified as the top 4 from each group:\n",
    "* Financial Data:\n",
    "    - 'exercised_stock_options'\t25.09754153\n",
    "    - 'total_stock_value'\t24.46765405\n",
    "    - 'bonus'\t21.06000171\n",
    "    - 'salary'\t18.57570327\n",
    "\n",
    "\n",
    "\n",
    "* Email Data:\n",
    "    - 'shared_receipt_with_poi'\t4.61945732\n",
    "    - 'from_poi_to_this_person'\t2.43137891\n",
    "    - 'from_this_person_to_poi'\t1.0853069\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now i am going to combine these feature to extract the top overal features from this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing financial_email_features k scores: \n",
      "[ 21.71552656  21.05899501  17.8573624   15.14904119   6.8822438\n",
      "   4.1460684    1.90840396   0.24111688]\n"
     ]
    }
   ],
   "source": [
    "financial_email_features = ['poi','exercised_stock_options','total_stock_value','bonus','salary','shared_receipt_with_poi','from_poi_to_this_person','from_this_person_to_poi','from_messages']\n",
    "financial_email_data = featureFormat(my_dataset, financial_email_features, sort_keys = True)\n",
    "labels, financial_email_features = targetFeatureSplit(financial_email_data)\n",
    "\n",
    "# select 4 best features using SelectKBest\n",
    "test3 = SelectKBest(k=4)\n",
    "fit3 = test3.fit(financial_email_features,labels)\n",
    "\n",
    "#numpy.set_printoptions(precision=10)\n",
    "print \"printing financial_email_features k scores: \\n\", (fit3.scores_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running SelectKBest on the top 4 features from each group combined, I observed the following K scores:\n",
    "\n",
    "Feature \t               Score\n",
    "- 'exercised_stock_options'\t21.71552656\n",
    "- 'total_stock_value'\t21.05899501\n",
    "- 'bonus'\t17.8573624\n",
    "- 'salary'\t15.14904119\n",
    "- 'shared_receipt_with_poi'\t6.8822438\n",
    "- 'from_poi_to_this_person'\t4.1460684\n",
    "- 'from_this_person_to_poi'\t1.90840396\n",
    "- 'from_messages'\t0.24111688\n",
    "\n",
    "\n",
    " Features from the financial data seem to be the best features to use to input them into our classifier. I'm going to compare this when I run SelectKBest on all features and also to SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing full_features k scores: \n",
      "[ 18.57570327   0.21705893   8.86672154   7.2427304   21.06000171\n",
      "   0.06498431  11.59554766  24.46765405   6.23420114  25.09754153\n",
      "   4.20497086  10.07245453   9.34670079   2.10765594   1.69882435\n",
      "   5.34494152   0.1641645    2.42650813   8.74648553]\n"
     ]
    }
   ],
   "source": [
    "full_feature_list = ['poi','salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees','to_messages','from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "full_data = featureFormat(my_dataset, full_feature_list, sort_keys = True)\n",
    "labels, full_features = targetFeatureSplit(full_data)\n",
    "\n",
    "# select 4 best features using SelectKBest\n",
    "test4 = SelectKBest(k=4)\n",
    "fit4 = test4.fit(full_features,labels)\n",
    "\n",
    "#numpy.set_printoptions(precision=10)\n",
    "print \"printing full_features k scores: \\n\", (fit4.scores_)\n",
    "\n",
    "feature = fit4.transform(full_features)\n",
    "\n",
    "#print full_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running SelectKBest on the entire feature list, excluding email address, I observed the following K scores:\n",
    "Feature \tScore\n",
    "- 'exercised_stock_options'\t25.09754153\n",
    "- 'total_stock_value'\t24.46765405\n",
    "- 'bonus'\t21.06000171\n",
    "- 'salary'\t18.57570327\n",
    "- 'deferred_income'\t11.59554766\n",
    "- 'long_term_incentive'\t10.07245453\n",
    "- 'restricted_stock'\t9.34670079\n",
    "- total_payments'\t8.86672154\n",
    "- 'shared_receipt_with_poi'\t8.74648553\n",
    "- 'loan_advances'\t7.2427304\n",
    "- 'expenses'\t6.23420114\n",
    "- 'from_poi_to_this_person'\t5.34494152\n",
    "- 'other'\t4.20497086\n",
    "- 'from_this_person_to_poi'\t2.42650813\n",
    "- 'director_fees'\t2.10765594\n",
    "- 'to_messages'\t1.69882435\n",
    "- 'deferral_payments'\t0.21705893\n",
    "- 'from_messages'\t0.1641645\n",
    "- 'restricted_stock_deferred'\t0.06498431\n",
    "\n",
    "\n",
    "As seen, the top 4 features from this list is the same when I picked out the top 4 features from each group and ran SelectKBest on the combined list. Lets see if this is the same when using Selectpercentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing full_features k scores: \n",
      "[ 18.57570327   0.21705893   8.86672154   7.2427304   21.06000171\n",
      "   0.06498431  11.59554766  24.46765405   6.23420114  25.09754153\n",
      "   4.20497086  10.07245453   9.34670079   2.10765594   1.69882435\n",
      "   5.34494152   0.1641645    2.42650813   8.74648553]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "test5 =  SelectPercentile(f_classif, percentile=10)\n",
    "fit5 = test5.fit(full_features,labels)\n",
    "\n",
    "#numpy.set_printoptions(precision=10)\n",
    "print \"printing full_features k scores: \\n\", (fit5.scores_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running SelectPercentile, I get the same scores as I did with SelectKBest. I think i found the features i want to use with my classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "features_list = ['poi','salary',  'bonus', 'total_stock_value', 'exercised_stock_options']\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(full_data)\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#clf = GaussianNB()\n",
    "#clf = clf = tree.DecisionTreeClassifier(min_samples_split = 40)\n",
    "#clf = RandomForestClassifier()\n",
    "clf = SVC()\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886363636364\n"
     ]
    }
   ],
   "source": [
    "# Testing Naive Bayes Classifier with no paramter tunes\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved the following metrics with Naive Bayes with no parameter tunes:\n",
    "\n",
    "- Accuracy: 0.84677\t\n",
    "- Precision: 0.50312\n",
    "- Recall: 0.32300\n",
    "- F1: 0.39342\tF2: 0.34791\n",
    "- Total predictions: 13000\n",
    "- True positives:  646\n",
    "- False positives:  638\n",
    "- False negatives: 1354\n",
    "- True negatives: 10362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.840909090909\n"
     ]
    }
   ],
   "source": [
    "# Testing Decision Tree Classifier with no paramter tunes\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved the following metrics with Decision Tree with no parameter tunes:\n",
    "\n",
    "- Accuracy: 0.82338\n",
    "- Precision: 0.26508\n",
    "- Recall: 0.08350\n",
    "- F1: 0.12700\tF2: 0.09676\n",
    "- Total predictions: 13000\n",
    "- True positives:  167\n",
    "- False positives:  463\n",
    "- False negatives: 1833\n",
    "- True negatives: 10537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863636363636\n"
     ]
    }
   ],
   "source": [
    "# Testing Random Forrest with no parameter tunes\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved the following metrics with Random Forest with no parameter tunes:\n",
    "\n",
    "- Accuracy: 0.84500\n",
    "- Precision: 0.49232\n",
    "- Recall: 0.24050\n",
    "- F1: 0.32314\tF2: 0.26791\n",
    "- Total predictions: 13000\n",
    "- True positives:  481\n",
    "- False positives:  496\n",
    "- False negatives: 1519\n",
    "- True negatives: 10504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886363636364\n"
     ]
    }
   ],
   "source": [
    "# Testing SVM with no parameter tunes\n",
    "clf.fit(features_train,labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved the following metrics with Random Forest with no parameter tunes:\n",
    "Precision or recall may be undefined due to a lack of true positive predicitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a divide by zero when trying out: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n"
     ]
    }
   ],
   "source": [
    "# %load tester.py\n",
    "#!/usr/bin/pickle\n",
    "\n",
    "\"\"\" a basic script for importing student's POI identifier,\n",
    "    and checking the results that they get from it \n",
    " \n",
    "    requires that the algorithm, dataset, and features list\n",
    "    be written to my_classifier.pkl, my_dataset.pkl, and\n",
    "    my_feature_list.pkl, respectively\n",
    "\n",
    "    that process should happen at the end of poi_id.py\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"r\") as clf_infile:\n",
    "        clf = pickle.load(clf_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"r\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"r\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
